<!DOCTYPE html><html lang="null"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Spark Storage | ShallWe Talk</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/7.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Spark Storage</h1><a id="logo" href="/.">ShallWe Talk</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Spark Storage</h1><div class="post-meta">Jun 14, 2015<span> | </span><span class="category"><a href="/categories/source-code/">source code</a><a href="/categories/source-code/Spark/">Spark</a></span></div><div class="post-content"><p>我们终于从Schedule到Execute又写到BlockManager了。这是carolz最早开始好奇的地方，但是不看完前两个部分真是完全没办法看这个部分呢。所以其实Spark的几个大块内容(schedule, execute, blockmanager, network)我们只剩下这个没有好好看过了，不禁有点小激动呢，感觉距离源码看完的一天又近了一步。话说最近读了Intel关于Spark GC优化的<a href="https://databricks.com/blog/2015/05/28/tuning-java-garbage-collection-for-spark-applications.html" target="_blank" rel="external">文章</a>，感觉改源码这件事情还是蛮炫酷的。虽然之前我们也动手改过，然而并不能算一次比较成功的修改。前路漫漫~  </p>
<p>好了闲话少叙，在<a href="http://6carol6.github.io/blog/2015/06/01/spark-execute/" target="_blank" rel="external">SparkExecute</a>中我们略过了ShuffledRDD之前的RDD是怎么往bucket里写数据的，也略过了Shuffled是怎么读这个数据的。在这篇文章里我们正要好好看看这件事情。<br><a id="more"></a></p>
<p>####1 写数据####</p>
<p>写数据是一个ShuffleMapTask的一部分。当这个Task执行到最后一个RDD.compute结束就应该写数据了。  </p>
<p>我们从ShuffleMapTask的runTask开始看起。看shuffle.writers(bucketId).write(pair)  </p>
<p>我们截取ShuffleMapTask的runTask的跟这个shuffle.writers有关的片段：  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> shuffleBlockManager = blockManager.shuffleBlockManager</div><div class="line"><span class="keyword">var</span> shuffle: <span class="type">ShuffleWriterGroup</span> = <span class="literal">null</span></div><div class="line"></div><div class="line">shuffle = shuffleBlockManager.forMapTask(dep.shuffleId, partitionId, numOutputSplits, ser)</div><div class="line"></div><div class="line"><span class="keyword">for</span>(elem &lt;- rdd.iterator(split, context))&#123;</div><div class="line">  <span class="keyword">val</span> pair = elem.asInstanceOf[<span class="type">Product2</span>[<span class="type">Any</span>, <span class="type">Any</span>]]</div><div class="line">  <span class="keyword">val</span> bucketId = dep.partitioner.getPartition(pair._1)</div><div class="line">  shuffle.writers(bucketId).write(pair)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>首先看一下bucketId。这里的dep.partitioner得到的是combineByKey的时候传进来的new HashPartitioner(numPartitions)。  </p>
<p>=================<strong>关于HashPartitioner</strong>=================  </p>
<p>Partitioner.scala  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment"> * A [[org.apache.spark.Partitioner]] that implements hash-based partitioning using</span></div><div class="line"><span class="comment"> * Java's `Object.hashCode`.</span></div><div class="line"><span class="comment"> *</span></div><div class="line"><span class="comment"> * Java arrays have hashCodes that are based on the arrays' identities rather than their contents,</span></div><div class="line"><span class="comment"> * so attempting to partition an RDD[Array[_]] or RDD[(Array[_], _)] using a HashPartitioner will</span></div><div class="line"><span class="comment"> * produce an unexpected or incorrect result.</span></div><div class="line"><span class="comment"> */</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">HashPartitioner</span>(<span class="params">partitions: <span class="type">Int</span></span>) <span class="keyword">extends</span> <span class="title">Partitioner</span> </span>&#123;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">numPartitions</span> </span>= partitions</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getPartition</span></span>(key: <span class="type">Any</span>): <span class="type">Int</span> = key <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="literal">null</span> =&gt; <span class="number">0</span></div><div class="line">    <span class="keyword">case</span> _ =&gt; <span class="type">Utils</span>.nonNegativeMod(key.hashCode, numPartitions)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">equals</span></span>(other: <span class="type">Any</span>): <span class="type">Boolean</span> = other <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> h: <span class="type">HashPartitioner</span> =&gt;</div><div class="line">      h.numPartitions == numPartitions</div><div class="line">    <span class="keyword">case</span> _ =&gt;</div><div class="line">      <span class="literal">false</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Utils.scala  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* Calculates 'x' modulo 'mod', takes to consideration sign of x,</span></div><div class="line"><span class="comment"> * i.e. if 'x' is negative, than 'x' % 'mod' is negative too</span></div><div class="line"><span class="comment"> * so function return (x % mod) + mod in that case.</span></div><div class="line"><span class="comment"> */</span></div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">nonNegativeMod</span></span>(x: <span class="type">Int</span>, mod: <span class="type">Int</span>): <span class="type">Int</span> = &#123;</div><div class="line">   <span class="keyword">val</span> rawMod = x % mod</div><div class="line">   rawMod + (<span class="keyword">if</span> (rawMod &lt; <span class="number">0</span>) mod <span class="keyword">else</span> <span class="number">0</span>)</div><div class="line"> &#125;</div></pre></td></tr></table></figure>
<p>总之HashParititioner.getPartitioner(key: Any)的意思就是根据key，返回一个hash值</p>
<!--lang:scala-->
<pre><code>if(key.hashCode &gt; 0){
  key.hashCode % numPartitions
}else{
  (key.hashCode % numPartitions) + numPartitions
}
</code></pre><p>=================<strong>HashPartitioner看完啦</strong>===============  </p>
<p>直接来看这个shuffle，根据赋值我们知道它是一个ShuffleWriterGroup，然后shuffle.writers是一个Array[BlockObjectWriter]，也就是说，根据bucketId，我们取出了一个BlockObjectWriter，然后往里面写一个pair。  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> writers: <span class="type">Array</span>[<span class="type">BlockObjectWriter</span>] = <span class="keyword">if</span> (consolidateShuffleFiles) &#123;</div><div class="line">  fileGroup = getUnusedFileGroup()</div><div class="line">  <span class="type">Array</span>.tabulate[<span class="type">BlockObjectWriter</span>](numBuckets) &#123; bucketId =&gt;</div><div class="line">    <span class="keyword">val</span> blockId = <span class="type">ShuffleBlockId</span>(shuffleId, mapId, bucketId)</div><div class="line">    blockManager.getDiskWriter(blockId, fileGroup(bucketId), serializer, bufferSize)</div><div class="line">  &#125;</div><div class="line">&#125; <span class="keyword">else</span> &#123;</div><div class="line">  <span class="comment">//上面那个if语句可以暂时忽略掉，因为那个值默认是false</span></div><div class="line">  <span class="type">Array</span>.tabulate[<span class="type">BlockObjectWriter</span>](numBuckets) &#123; bucketId =&gt;</div><div class="line">	<span class="keyword">val</span> blockId = <span class="type">ShuffleBlockId</span>(shuffleId, mapId, bucketId) </div><div class="line">	<span class="keyword">val</span> blockFile = blockManager.diskBlockManager.getFile(blockId)</div><div class="line">	<span class="comment">// Because of previous failures, the shuffle file may already exist on this machine.</span></div><div class="line">	<span class="comment">// If so, remove it.</span></div><div class="line">	<span class="keyword">if</span> (blockFile.exists) &#123;</div><div class="line">	  <span class="keyword">if</span> (blockFile.delete()) &#123;</div><div class="line">		logInfo(<span class="string">s"Removed existing shuffle file <span class="subst">$blockFile</span>"</span>)</div><div class="line">	  &#125; <span class="keyword">else</span> &#123;</div><div class="line">		logWarning(<span class="string">s"Failed to remove existing shuffle file <span class="subst">$blockFile</span>"</span>)</div><div class="line">	  &#125;</div><div class="line">	&#125;</div><div class="line">	blockManager.getDiskWriter(blockId, blockFile, serializer, bufferSize)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>由此可知shuffle.writers(bucketId)获得一个DiskWriter。这个DiskWriter是由(blockId, blockFile)。而这个blockFile也是由blockId得到的。那么这个blockId又是怎么来的呢？  </p>
<p>blockId是由(shuffleId, mapId, bucketId)得到的。shuffleId就是dep.shuffleId，mapId就是partitionId，bucketId应该就是传进来的参数？  </p>
<p>首先看一下ShuffleBlockId的格式  </p>
<p>BlockId.scala  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@DeveloperApi</span></div><div class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">ShuffleBlockId</span>(<span class="params">shuffleId: <span class="type">Int</span>, mapId: <span class="type">Int</span>, reduceId: <span class="type">Int</span></span>)</span></div><div class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">BlockId</span> </span>&#123;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">name</span> </span>= <span class="string">"shuffle_"</span> + shuffleId + <span class="string">"_"</span> + mapId + <span class="string">"_"</span> + reduceId</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>再去看一眼blockFile  </p>
<p>DiskBlockManager.scala</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getFile</span></span>(filename: <span class="type">String</span>): <span class="type">File</span> = &#123;</div><div class="line">  <span class="comment">// Figure out which local directory it hashes to, and which subdirectory in that</span></div><div class="line">  <span class="keyword">val</span> hash = <span class="type">Utils</span>.nonNegativeHash(filename)</div><div class="line">  <span class="keyword">val</span> dirId = hash % localDirs.length</div><div class="line">  <span class="keyword">val</span> subDirId = (hash / localDirs.length) % subDirsPerLocalDir</div><div class="line"></div><div class="line">  <span class="comment">// Create the subdirectory if it doesn't already exist</span></div><div class="line">  <span class="keyword">var</span> subDir = subDirs(dirId)(subDirId)</div><div class="line">  <span class="keyword">if</span> (subDir == <span class="literal">null</span>) &#123;</div><div class="line">    subDir = subDirs(dirId).synchronized &#123;</div><div class="line">      <span class="keyword">val</span> old = subDirs(dirId)(subDirId)</div><div class="line">      <span class="keyword">if</span> (old != <span class="literal">null</span>) &#123;</div><div class="line">        old</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="keyword">val</span> newDir = <span class="keyword">new</span> <span class="type">File</span>(localDirs(dirId), <span class="string">"%02x"</span>.format(subDirId))</div><div class="line">        newDir.mkdir()</div><div class="line">        subDirs(dirId)(subDirId) = newDir</div><div class="line">        newDir</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">new</span> <span class="type">File</span>(subDir, filename)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>然后文件有了，就要拿到DiskWriter了。  </p>
<p>BlockManager.scala  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment"> * A short circuited method to get a block writer that can write data directly to disk.</span></div><div class="line"><span class="comment"> * The Block will be appended to the File specified by filename. This is currently used for</span></div><div class="line"><span class="comment"> * writing shuffle files out. Callers should handle error cases.</span></div><div class="line"><span class="comment"> */</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getDiskWriter</span></span>(</div><div class="line">    blockId: <span class="type">BlockId</span>,</div><div class="line">    file: <span class="type">File</span>,</div><div class="line">    serializer: <span class="type">Serializer</span>,</div><div class="line">    bufferSize: <span class="type">Int</span>): <span class="type">BlockObjectWriter</span> = &#123;</div><div class="line">  <span class="keyword">val</span> compressStream: <span class="type">OutputStream</span> =&gt; <span class="type">OutputStream</span> = wrapForCompression(blockId, _)</div><div class="line">  <span class="keyword">val</span> syncWrites = conf.getBoolean(<span class="string">"spark.shuffle.sync"</span>, <span class="literal">false</span>)</div><div class="line">  <span class="keyword">new</span> <span class="type">DiskBlockObjectWriter</span>(blockId, file, serializer, bufferSize, compressStream, syncWrites)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>BlockObjectWriter.scala  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">write</span></span>(i: <span class="type">Int</span>): <span class="type">Unit</span> = callWithTiming(out.write(i))</div><div class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">write</span></span>(b: <span class="type">Array</span>[<span class="type">Byte</span>]) = callWithTiming(out.write(b))</div><div class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">write</span></span>(b: <span class="type">Array</span>[<span class="type">Byte</span>], off: <span class="type">Int</span>, len: <span class="type">Int</span>) = callWithTiming(out.write(b, off, len))</div></pre></td></tr></table></figure>
<p>这里的callWithTimining的作用是记录下写文件花费的时间，然后把这次写文件的时间记录下来。  </p>
<p>至此，文件就写好了。  </p>
<p>综上所述，我们写了几个文件。这个几个文件名是<code>&quot;shuffle_&quot; + shuffleId + &quot;_&quot; + mapId + &quot;_&quot; + reduceId</code>的格式然后进行hash之后的结果。其中，</p>
<ul>
<li>shuffleId就是dep.shuffleId（每次自增1)</li>
<li>mapId就是partitionId<ul>
<li>就是当初新建ShuffleMapTask的时候的p。(p &lt;- 0 until stage.numPartitions)</li>
</ul>
</li>
<li>bucketId应该就是传进来的参数<ul>
<li>bucketId与每个pair._1的hashCode有关(基本就是pair._1.hashCode % numPartitions)。val bucketId = dep.partitioner.getPartition(pair._1)。</li>
</ul>
</li>
</ul>
<p>这里还会涉及到文件子目录的问题，我们先放一下，反正怎么写的到时候怎么读出来就行了。  </p>
<p>在pair都写到bucket了之后，我们还要做一些别的事情。  </p>
<ul>
<li>Commit the writes. Get the size of each bucket block (total block size).</li>
<li>Update shuffle metrics.<ul>
<li>new MapStatus(blockManager.blockManagerId, compressedSizes)</li>
</ul>
</li>
<li>Release the writers back to the shuffle block manager.</li>
<li>Execute the callbacks on task completion.</li>
</ul>
<p>至此这个Task就算是完成了。  </p>
<p>======================<strong>小看一下MapStatus</strong>========================  </p>
<p>这里MapStatus的建立非常重要，等下取数据也是要根据MapStatus取的。这货的建立需要blockManager.blockManagerId，这个值哪里来的呢？  </p>
<p>在executor初始化时，每一个executor都会有　　</p>
<pre><code>val _env = SparkEnv.create(conf, executorId, slaveHostname, 0, isDriver = false, isLocal = false)
SparkEnv.set(env)
</code></pre><p>也就是说，每个executor都有自己的SparkEnv。每个SparkEnv里又都新建了一个BlockManager，每个BlockManager都有一个BlockManagerId(executorId, connectionManager.id.host, connectionManager.id.port, nettyPort)  </p>
<p>BlockManagerId.scala  </p>
<pre><code>override def toString = &quot;BlockManagerId(%s, %s, %d, %d)&quot;.format(executorId, host, port, nettyPort)
</code></pre><p>===========================<strong>看完了</strong>==============================  </p>
<p>####2 读数据####</p>
<p>接下来我们就要从ShuffledRDD开始看读数据的过程了。  </p>
<p>ShuffledRDD.scala  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compute</span></span>(split: <span class="type">Partition</span>, context: <span class="type">TaskContext</span>): <span class="type">Iterator</span>[<span class="type">P</span>] = &#123;</div><div class="line">  <span class="keyword">val</span> shuffledId = dependencies.head.asInstanceOf[<span class="type">ShuffleDependency</span>[<span class="type">K</span>, <span class="type">V</span>]].shuffleId</div><div class="line">  <span class="keyword">val</span> ser = <span class="type">Serializer</span>.getSerializer(serializer)</div><div class="line">  <span class="type">SparkEnv</span>.get.shuffleFetcher.fetch[<span class="type">P</span>](shuffledId, split.index, context, ser)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>所以事情就是这样，这里需要根据shuffledId和split.index取数据了。  </p>
<p>========================<strong>关于shuffledId和split.index</strong>====================  </p>
<p>####1 ShuffledId####</p>
<p>早在<a href="http://6carol6.github.io/blog/2015/05/22/spark-scheduling/" target="_blank" rel="external">spark scheduling</a>这篇文章里讲<code>getMissingParentStages</code>的时候，有一个遍历<code>rdd.dependencies</code>的语句。这句话会调用各个rdd override的<code>getDependencies</code>，我们来看一下ShuffledRDD的<code>getDependencies</code>（<strong>这个函数只会被调用一次</strong>）  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getDependencies</span></span>: <span class="type">Seq</span>[<span class="type">Dependency</span>[_]] = &#123;</div><div class="line">  <span class="type">List</span>(<span class="keyword">new</span> <span class="type">ShuffleDependency</span>(prev, part, serializer))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>再看一下Dependency.scala  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment"> * :: DeveloperApi ::</span></div><div class="line"><span class="comment"> * Represents a dependency on the output of a shuffle stage.</span></div><div class="line"><span class="comment"> * @param rdd the parent RDD</span></div><div class="line"><span class="comment"> * @param partitioner partitioner used to partition the shuffle output</span></div><div class="line"><span class="comment"> * @param serializer [[org.apache.spark.serializer.Serializer Serializer]] to use. If set to null,</span></div><div class="line"><span class="comment"> *                   the default serializer, as specified by `spark.serializer` config option, will</span></div><div class="line"><span class="comment"> *                   be used.</span></div><div class="line"><span class="comment"> */</span></div><div class="line"><span class="meta">@DeveloperApi</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ShuffleDependency</span>[<span class="type">K</span>, <span class="type">V</span>](<span class="params"></span></span></div><div class="line"><span class="class"><span class="params">    @transient rdd: <span class="type">RDD</span>[_ &lt;: <span class="type">Product2</span>[<span class="type">K</span>, <span class="type">V</span>]],</span></span></div><div class="line"><span class="class"><span class="params">    val partitioner: <span class="type">Partitioner</span>,</span></span></div><div class="line"><span class="class"><span class="params">    val serializer: <span class="type">Serializer</span> = null</span>)</span></div><div class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">Dependency</span>(<span class="params">rdd.asInstanceOf[<span class="type">RDD</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">V</span>]]]</span>) </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">val</span> shuffleId: <span class="type">Int</span> = rdd.context.newShuffleId()</div><div class="line"></div><div class="line">  rdd.sparkContext.cleaner.foreach(_.registerShuffleForCleanup(<span class="keyword">this</span>))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里的rdd.context是一个SparkContext，rdd.context.newShuffleId其实就是在上一个shuffleId的基础上自增1而已。  </p>
<p>至此我们已经知道了<strong>ShuffledId是在划分stage的时候就分配了的，值是每次自增1的</strong>。  </p>
<p>####2 split.index####</p>
<p>这里的split来自iterator传进的参数，这个iterator往上追溯是在ShuffleMapTask新建的时候给赋值的。  </p>
<p>ShuffleMapTask.scala  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">var</span> split = <span class="keyword">if</span> (rdd == <span class="literal">null</span>) <span class="literal">null</span> <span class="keyword">else</span> rdd.partitions(partitionId)</div></pre></td></tr></table></figure>
<p>rdd.partitions(partitionId)得到的是一个Partition，这个Partition的index又是从哪来的呢？  </p>
<p>我们在<a href="http://6carol6.github.io/blog/2015/06/03/start-from-hadooprdd/" target="_blank" rel="external">start from HadoopRDD</a>中曾经说过，当<code>rdd.partitions</code>第一次被调用的时候，就会调用这个RDD override的<code>getPartitions</code>。<strong>这里我们假设就是第一次调用吧（因为再也找不到上层了）</strong>于是就有了这个结果：  </p>
<p>ShufffledRDD.scala  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getPartitions</span></span>: <span class="type">Array</span>[<span class="type">Partition</span>] = &#123;</div><div class="line">  <span class="type">Array</span>.tabulate[<span class="type">Partition</span>](part.numPartitions)(i =&gt; <span class="keyword">new</span> <span class="type">ShuffledRDDPartition</span>(i))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>所以说其实ShuffledRDD有其独特的Partition。  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">class</span> <span class="title">ShuffledRDDPartition</span>(<span class="params">val idx: <span class="type">Int</span></span>) <span class="keyword">extends</span> <span class="title">Partition</span> </span>&#123;</div><div class="line">  <span class="keyword">override</span> <span class="keyword">val</span> index = idx <span class="comment">//这就是split.index</span></div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">hashCode</span></span>(): <span class="type">Int</span> = idx</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>所以split.index就是那个i。就是从0到part.numPartitions的i。  </p>
<p>==========================<strong>解释结束</strong>==========================  </p>
<p>看到这里，我们就可以直接去取数据了。  </p>
<pre><code>SparkEnv.get.shuffleFetcher.fetch[P](shuffledId, split.index, context, ser)
</code></pre><p>这里的SparkEnv.get.shuffleFetcher实际上是BlockStoreShuffleFetcher  </p>
<p>BlockStoreShuffleFetcher.scala  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">class</span> <span class="title">BlockStoreShuffleFetcher</span> <span class="keyword">extends</span> <span class="title">ShuffleFetcher</span> <span class="keyword">with</span> <span class="title">Logging</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">fetch</span></span>[<span class="type">T</span>](</div><div class="line">      shuffleId: <span class="type">Int</span>,</div><div class="line">      reduceId: <span class="type">Int</span>,</div><div class="line">      context: <span class="type">TaskContext</span>,</div><div class="line">      serializer: <span class="type">Serializer</span>)</div><div class="line">    : <span class="type">Iterator</span>[<span class="type">T</span>] =</div><div class="line">  &#123;</div><div class="line"></div><div class="line">    logDebug(<span class="string">"Fetching outputs for shuffle %d, reduce %d"</span>.format(shuffleId, reduceId))</div><div class="line">    <span class="keyword">val</span> blockManager = <span class="type">SparkEnv</span>.get.blockManager</div><div class="line"></div><div class="line">    <span class="keyword">val</span> startTime = <span class="type">System</span>.currentTimeMillis</div><div class="line">	<span class="comment">//从Master得到map output file 的location</span></div><div class="line">    <span class="keyword">val</span> statuses = <span class="type">SparkEnv</span>.get.mapOutputTracker.getServerStatuses(shuffleId, reduceId)</div><div class="line">    logDebug(<span class="string">"Fetching map output location for shuffle %d, reduce %d took %d ms"</span>.format(</div><div class="line">      shuffleId, reduceId, <span class="type">System</span>.currentTimeMillis - startTime))</div><div class="line"></div><div class="line">    <span class="keyword">val</span> splitsByAddress = <span class="keyword">new</span> <span class="type">HashMap</span>[<span class="type">BlockManagerId</span>, <span class="type">ArrayBuffer</span>[(<span class="type">Int</span>, <span class="type">Long</span>)]]</div><div class="line">    <span class="keyword">for</span> (((address, size), index) &lt;- statuses.zipWithIndex) &#123;</div><div class="line">      splitsByAddress.getOrElseUpdate(address, <span class="type">ArrayBuffer</span>()) += ((index, size))</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> blocksByAddress: <span class="type">Seq</span>[(<span class="type">BlockManagerId</span>, <span class="type">Seq</span>[(<span class="type">BlockId</span>, <span class="type">Long</span>)])] = splitsByAddress.toSeq.map &#123;</div><div class="line">      <span class="keyword">case</span> (address, splits) =&gt;</div><div class="line">        (address, splits.map(s =&gt; (<span class="type">ShuffleBlockId</span>(shuffleId, s._1, reduceId), s._2)))</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">unpackBlock</span></span>(blockPair: (<span class="type">BlockId</span>, <span class="type">Option</span>[<span class="type">Iterator</span>[<span class="type">Any</span>]])) : <span class="type">Iterator</span>[<span class="type">T</span>] = &#123;</div><div class="line">      <span class="keyword">val</span> blockId = blockPair._1</div><div class="line">      <span class="keyword">val</span> blockOption = blockPair._2</div><div class="line">      blockOption <span class="keyword">match</span> &#123;</div><div class="line">        <span class="keyword">case</span> <span class="type">Some</span>(block) =&gt; &#123;</div><div class="line">          block.asInstanceOf[<span class="type">Iterator</span>[<span class="type">T</span>]]</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">case</span> <span class="type">None</span> =&gt; &#123;</div><div class="line">          blockId <span class="keyword">match</span> &#123;</div><div class="line">            <span class="keyword">case</span> <span class="type">ShuffleBlockId</span>(shufId, mapId, _) =&gt;</div><div class="line">              <span class="keyword">val</span> address = statuses(mapId.toInt)._1</div><div class="line">              <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">FetchFailedException</span>(address, shufId.toInt, mapId.toInt, reduceId, <span class="literal">null</span>)</div><div class="line">            <span class="keyword">case</span> _ =&gt;</div><div class="line">              <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(</div><div class="line">                <span class="string">"Failed to get block "</span> + blockId + <span class="string">", which is not a shuffle block"</span>)</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> blockFetcherItr = blockManager.getMultiple(blocksByAddress, serializer)</div><div class="line">    <span class="keyword">val</span> itr = blockFetcherItr.flatMap(unpackBlock)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> completionIter = <span class="type">CompletionIterator</span>[<span class="type">T</span>, <span class="type">Iterator</span>[<span class="type">T</span>]](itr, &#123;</div><div class="line">      <span class="keyword">val</span> shuffleMetrics = <span class="keyword">new</span> <span class="type">ShuffleReadMetrics</span></div><div class="line">      shuffleMetrics.shuffleFinishTime = <span class="type">System</span>.currentTimeMillis</div><div class="line">      shuffleMetrics.fetchWaitTime = blockFetcherItr.fetchWaitTime</div><div class="line">      shuffleMetrics.remoteBytesRead = blockFetcherItr.remoteBytesRead</div><div class="line">      shuffleMetrics.totalBlocksFetched = blockFetcherItr.totalBlocks</div><div class="line">      shuffleMetrics.localBlocksFetched = blockFetcherItr.numLocalBlocks</div><div class="line">      shuffleMetrics.remoteBlocksFetched = blockFetcherItr.numRemoteBlocks</div><div class="line">      context.taskMetrics.shuffleReadMetrics = <span class="type">Some</span>(shuffleMetrics)</div><div class="line">    &#125;)</div><div class="line"></div><div class="line">    <span class="keyword">new</span> <span class="type">InterruptibleIterator</span>[<span class="type">T</span>](context, completionIter)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>首先就是要getServerStatus(shuffleId, reduceId)，这个函数主要做的事情就是：  </p>
<blockquote>
<p>Called from executors to get the server URIs and output sizes of the map outputs of a given shuffle.</p>
</blockquote>
<p>首先就是根据shuffleId看看map output在不在本地啊，如果不在的话，就要fetch了。然后看看是不是有别人在fetch啊，如果有的话就要等一等啊。等完之后就执行fetchedStatuses = mapStatuses.get(shuffleId).orNull这一步是在考虑如果有人在这个get和刚才的fetching.synchronized之间也在fetch怎么办。总之这里都是考虑同步的。  </p>
<p>下面截取getServerStatus(shuffleId, reduceId)比较重要的部分  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> fetchedBytes =</div><div class="line">  askTracker(<span class="type">GetMapOutputStatuses</span>(shuffleId)).asInstanceOf[<span class="type">Array</span>[<span class="type">Byte</span>]]</div><div class="line">fetchedStatuses = <span class="type">MapOutputTracker</span>.deserializeMapStatuses(fetchedBytes)</div><div class="line">logInfo(<span class="string">"Got the output locations"</span>)</div><div class="line">mapStatuses.put(shuffleId, fetchedStatuses)</div><div class="line"></div><div class="line"><span class="keyword">return</span> <span class="type">MapOutputTracker</span>.convertMapStatuses(shuffleId, reduceId, fetchedStatuses)</div></pre></td></tr></table></figure>
<p>askTracker主要就是</p>
<pre><code>val future = trackerActor.ask(message)(timeout)
  Await.result(future, timeout)
</code></pre><p>trackerActor是一个<code>ActorRef</code>，这是akka里面的一个类。发出去的消息是一个MapOutputTrackerMessage。总之就是向Master询问output locations然后得到回复，返回<code>MapOutputTracker.convertMapStatuses(shuffleId, reduceId, fetchedStatuses)</code>。  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Convert an array of MapStatuses to locations and sizes for a given reduce ID. If</span></div><div class="line"><span class="comment">// any of the statuses is null (indicating a missing location due to a failed mapper),</span></div><div class="line"><span class="comment">// throw a FetchFailedException.</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">convertMapStatuses</span></span>(</div><div class="line">      shuffleId: <span class="type">Int</span>,</div><div class="line">      reduceId: <span class="type">Int</span>,</div><div class="line">      statuses: <span class="type">Array</span>[<span class="type">MapStatus</span>]): <span class="type">Array</span>[(<span class="type">BlockManagerId</span>, <span class="type">Long</span>)] = &#123;</div><div class="line">  assert (statuses != <span class="literal">null</span>)</div><div class="line">  statuses.map &#123;</div><div class="line">    status =&gt;</div><div class="line">      <span class="keyword">if</span> (status == <span class="literal">null</span>) &#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">FetchFailedException</span>(<span class="literal">null</span>, shuffleId, <span class="number">-1</span>, reduceId,</div><div class="line">          <span class="keyword">new</span> <span class="type">Exception</span>(<span class="string">"Missing an output location for shuffle "</span> + shuffleId))</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        (status.location, decompressSize(status.compressedSizes(reduceId)))</div><div class="line">      &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>通过Array的map方法，可以把statuses里的status全部变成(status.location, size)的格式。  </p>
<p>可以看出来，获得的地址信息是(address, size)数组格式的，也就是说会有很多个地址（shuffle的数据来自多个嘛，可以理解）。BlockStoreShuffleFetcher会用zipWithIndex方法把这些地址编上号（从0开始累加），变成((address, size), index)，然后以((index, size))的格式放到splitsByAddress(address, ArrayBuffer())里。这个address其实就是BlockManagerId。总之就是得到了地址啥的，然后就要从远端去获取数据了。  </p>
<pre><code>val blockFetcherItr = blockManager.getMultiple(blocksByAddress, serializer)
val itr = blockFetcherItr.flatMap(unpackBlock)
</code></pre><p>先看blockManager.getMultile  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment"> * Get multiple blocks from local and remote block manager using their BlockManagerIds. Returns</span></div><div class="line"><span class="comment"> * an Iterator of (block ID, value) pairs so that clients may handle blocks in a pipelined</span></div><div class="line"><span class="comment"> * fashion as they're received. Expects a size in bytes to be provided for each block fetched,</span></div><div class="line"><span class="comment"> * so that we can control the maxMegabytesInFlight for the fetch.</span></div><div class="line"><span class="comment"> */</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getMultiple</span></span>(</div><div class="line">    blocksByAddress: <span class="type">Seq</span>[(<span class="type">BlockManagerId</span>, <span class="type">Seq</span>[(<span class="type">BlockId</span>, <span class="type">Long</span>)])],</div><div class="line">    serializer: <span class="type">Serializer</span>): <span class="type">BlockFetcherIterator</span> = &#123;</div><div class="line">  <span class="keyword">val</span> iter =</div><div class="line">    <span class="keyword">if</span> (conf.getBoolean(<span class="string">"spark.shuffle.use.netty"</span>, <span class="literal">false</span>)) &#123;</div><div class="line">      <span class="keyword">new</span> <span class="type">BlockFetcherIterator</span>.<span class="type">NettyBlockFetcherIterator</span>(<span class="keyword">this</span>, blocksByAddress, serializer)</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="keyword">new</span> <span class="type">BlockFetcherIterator</span>.<span class="type">BasicBlockFetcherIterator</span>(<span class="keyword">this</span>, blocksByAddress, serializer)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">  iter.initialize()</div><div class="line">  iter</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>返回值是一个initialize()过后的BasicBlockFetcherIterator（因为默认是不用Netty的）  </p>
<p>这个初始化做的事情有：  </p>
<ul>
<li>Split local and remote blocks</li>
<li>Add the remote requessts into our queue in a random order</li>
<li>Send out initial requests for blocks, up to our maxBytesInFlight</li>
<li>Get Local Blocks<ul>
<li>Get the local blocks while remote blocks are being fetched. Note that it’s okay to do these all at once because they will just memory-map some files, so they won’t consume any memory that might exceed our maxBytesInFlight</li>
</ul>
</li>
</ul>
<p>然而我们并没有在代码中看出从远端获取能跟本地获取同时进行╮(╯▽╰)╭  </p>
<p>ok，然后执行blockFetcherItr.flatMap(unpackBlock)  </p>
<p>然后我不想看了，明天继续。  </p>
</div><div class="tags"></div><div class="post-nav"><a href="/2015/06/16/2015-06-16-congmingdejimo/" class="pre">扒谱子什么的 X 聪明的寂寞</a><a href="/2015/06/14/2015-06-14-leetcode226-invert-binary-tree/" class="next">LeetCode226: Invert Binary Tree</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://yoursite.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Beijing/">Beijing</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/C语言学习笔记/">C语言学习笔记</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Security/">Security</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spark/">Spark</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Spark/RDD/">RDD</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Spark/RDD/source-code/">source code</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spark/configuration/">configuration</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/blog/">blog</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/coding/">coding</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/coding/compiler/">compiler</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/dp/">dp</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/language/">language</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/language/Japanese/">Japanese</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/language/Japanese/lyric/">lyric</a></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/leetcode/">leetcode</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/leetcode/HashTable/">HashTable</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/leetcode/Two-Pointers/">Two Pointers</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/leetcode/divide-and-conquer/">divide and conquer</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/leetcode/dp/">dp</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/mapreduce/">mapreduce</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/music/">music</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/music/guitar/">guitar</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/paper/">paper</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/paper/NLP/">NLP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/paper/scheduler/">scheduler</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/programming-language/">programming language</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/python/matplotlib/">matplotlib</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/software-engineer/">software engineer</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/software-engineer/API/">API</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/source-code/">source code</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/source-code/JXIO/">JXIO</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/source-code/Spark/">Spark</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/spark/">spark</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/unity/">unity</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/unity/animation/">animation</a></li></ul></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/07/08/2017-07-08-unity-animation/">unity-animation</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/09/2017-04-09-dynamic-resource-allocation/">Dynamic Resource Allocation</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/06/2017-03-06-swprintf/">来聊一聊C++的string</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/08/13/2016-08-13-beijing/">出去玩-北京</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/05/31/2016-05-31-running-spark-on-mesos/">Running Spark on Mesos</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/04/12/2016-04-12-spark-summary/">Spark小结</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/03/25/2016-03-25-the-number-of-the-increasing-sub-sequences/">一个数组的递增子序列的个数</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/12/13/2015-12-13-factorial-nonzero-suffix/">求N!的后9位不为0的数</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/09/24/2015-09-24-recent-performance-improvements-in-apache-spark/">Recent Performance Improvements in Apache Spark: SQL, Python, DataFrame, and More</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/08/15/2015-08-15-matplotlib/">Matplotlib整理</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2017 <a href="/." rel="nofollow">ShallWe Talk.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div><script src="//dn-lbstatics.qbox.me/lbservice/busuanzi/2.0/busuanzi.mini.js"/></script>
<span id="busuanzi_container_site_uv">已经有<span id="busuanzi_value_site_uv"></span>人次访问carolz的小站啦 ( •̀ ω •́ )y</span>
</ br></ br></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>